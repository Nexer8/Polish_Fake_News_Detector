{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cX-nXlspqesI"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rvdXqfSKPXc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef6b1be0-dedd-4862-ebc6-1ad1d63684c3"
      },
      "source": [
        "!pip install -i https://pypi.clarin-pl.eu lpmn_client"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxS2kfBwqdar",
        "outputId": "e7db9d53-063d-4f88-e76b-a00112b9509c"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "import re, string\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "# from keras.layers import Dense, Embedding, LSTM, Dropout\n",
        "# from keras.models import Sequential\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.losses import sparse_categorical_crossentropy\n",
        "from lpmn_client.src.requester import Requester\n",
        "import zipfile\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import xml.etree.ElementTree as ET\n",
        "import numbers\n",
        "import decimal\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8c1FijT1mrnh"
      },
      "source": [
        "# Data loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dy75juyZrT2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "97eb581f-3abd-4dfc-b270-cb8ab6da4b27"
      },
      "source": [
        "data_path = 'data/citations.csv'\n",
        "tfidf_features_path = 'data/tfidf_all_features.csv'\n",
        "\n",
        "pd.set_option('display.max_rows', 10)\n",
        "pd.set_option('display.max_colwidth', 120)\n",
        "\n",
        "df = pd.read_csv(data_path)\n",
        "df = df.dropna()\n",
        "df = df.reset_index(drop=True)\n",
        "# df.info()\n",
        "\n",
        "classes_names = {0: 'Fałsz', 1: 'Prawda', 2: \"Manipulacja\", 3: \"Nieweryfikowalne\"}\n",
        "df['label'].replace({'Fałsz': 0, 'Prawda': 1, 'Manipulacja': 2, 'Nieweryfikowalne': 3}, inplace=True)\n",
        "df = df[(df['label'] == 0) | (df['label'] == 1)]\n",
        "# X.head()\n",
        "# y.head(10)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73PqDGDXRSJB"
      },
      "source": [
        "# Feature creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEHv3t1ARYQP"
      },
      "source": [
        "def count_uppercase_letters(text):\n",
        "    count = sum([1 for char in text if char.isupper()])\n",
        "    return (count / (len(text) - text.count(' '))) * 100\n",
        "\n",
        "\n",
        "def count_exclamation_marks(text):\n",
        "    count = text.count('!')\n",
        "    return (count / (len(text) - text.count(' '))) * 100\n",
        "\n",
        "\n",
        "def count_question_marks(text):\n",
        "    count = text.count('?')\n",
        "    return (count / (len(text) - text.count(' '))) * 100\n",
        "\n",
        "\n",
        "def count_quotation_marks(text):\n",
        "    count = text.count('\"')\n",
        "    return (count / (len(text) - text.count(' '))) * 100\n",
        "\n",
        "\n",
        "def count_punctuation(text):\n",
        "    count = sum([1 for char in text if char in string.punctuation])\n",
        "    return (count / (len(text) - text.count(' '))) * 100\n",
        "\n",
        "\n",
        "def count_text_length(text):\n",
        "    return len(text) - text.count(' ')\n",
        "\n",
        "\n",
        "def get_sentiment(text):\n",
        "    requester = Requester('241393@student.pwr.edu.pl')\n",
        "    lpmn_query = 'any2txt|wcrft2|wsd|ccl_emo({\"lang\":\"polish\"})|ccl_emo_stats({' \\\n",
        "                 '\"lang\":\"polish\", \"split_paragraphs\": false})'\n",
        "\n",
        "    string_ids = requester.upload_strings([text])\n",
        "    response = requester.process_query(lpmn_query, [string_id.text for string_id in string_ids])\n",
        "    requester.download_response(response[0], './sentiment.zip')\n",
        "\n",
        "    try:\n",
        "        with zipfile.ZipFile('sentiment.zip', 'r') as archive:\n",
        "            with archive.open(archive.namelist()[0]) as data:\n",
        "                df = pd.read_csv(data, sep=';')\n",
        "\n",
        "        sentiment_value = sum([int(entry) for entry in df['Polarity'].values if\n",
        "                               (type(entry) == str and entry.isnumeric()) or isinstance(entry, (int, float, complex))])\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        sentiment_value = 0\n",
        "\n",
        "    return sentiment_value\n",
        "\n",
        "\n",
        "def count_positive_words():\n",
        "    try:\n",
        "        with zipfile.ZipFile('sentiment.zip', 'r') as archive:\n",
        "            with archive.open(archive.namelist()[0]) as data:\n",
        "                df = pd.read_csv(data, sep=';')\n",
        "\n",
        "        positive_words = (sum([1 for entry in df['Polarity'].values if\n",
        "                               (type(entry) == str and entry.isnumeric() or isinstance(entry,\n",
        "                                                                                       (int, float, complex))) and int(\n",
        "                                   entry) > 0]) / len(df['Polarity'])) * 100\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        positive_words = 0\n",
        "\n",
        "    return positive_words\n",
        "\n",
        "\n",
        "def count_negative_words():\n",
        "    try:\n",
        "        with zipfile.ZipFile('sentiment.zip', 'r') as archive:\n",
        "            with archive.open(archive.namelist()[0]) as data:\n",
        "                df = pd.read_csv(data, sep=';')\n",
        "\n",
        "        negative_words = (sum([1 for entry in df['Polarity'].values if\n",
        "                               (type(entry) == str and entry.isnumeric() or isinstance(entry,\n",
        "                                                                                       (int, float, complex))) and int(\n",
        "                                   entry) < 0]) / len(df['Polarity'])) * 100\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        negative_words = 0\n",
        "\n",
        "    return negative_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JWdvWr12hZa",
        "outputId": "f7b44809-da5d-4c0b-88d2-645237901cd4"
      },
      "source": [
        "# Run only if there is a need to regenerate all the features. Otherwise, go to Loading features.\n",
        "df['uppercase%'] = df['content'].apply(lambda x: count_uppercase_letters(x))\n",
        "df['exclamation_mark%'] = df['content'].apply(lambda x: count_exclamation_marks(x))\n",
        "df['question_mark%'] = df['content'].apply(lambda x: count_question_marks(x))\n",
        "df['quotation_mark%'] = df['content'].apply(lambda x: count_quotation_marks(x))\n",
        "df['punctuation%'] = df['content'].apply(lambda x: count_punctuation(x))\n",
        "df['length'] = df['content'].apply(lambda x: count_text_length(x))\n",
        "\n",
        "rows_list = []\n",
        "for index, row in df.iterrows():\n",
        "    dictionary = {'sentiment': get_sentiment(df.at[index, 'content']),\n",
        "                  'positive_words%': count_positive_words(),\n",
        "                  'negative_words%': count_negative_words()}\n",
        "\n",
        "    rows_list.append(dictionary)\n",
        "    print(f'Index: {index}')\n",
        "\n",
        "df = pd.concat([df.reset_index(drop=True), pd.DataFrame(rows_list).reset_index(drop=True)], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ps_WndVgf5WC"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXFt-ey6mqXj"
      },
      "source": [
        "df.to_csv(tfidf_features_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iOqXFSDmxdw"
      },
      "source": [
        "# Text preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ah8YXWTVZ0A7"
      },
      "source": [
        "def remove_punctuation(text):\n",
        "    no_punctuation_text = \"\".join([char for char in text if char not in string.punctuation])\n",
        "    return no_punctuation_text\n",
        "\n",
        "\n",
        "def lemmatize(text):\n",
        "    requester = Requester('241393@student.pwr.edu.pl')\n",
        "    lpmn_query = 'any2txt|wcrft2({\"guesser\":false, \"morfeusz2\":true})'\n",
        "\n",
        "    string_ids = requester.upload_strings([text])\n",
        "    response = requester.process_query(lpmn_query, [id.text for id in string_ids])\n",
        "    requester.download_response(response[0], './lem.zip')\n",
        "\n",
        "    lemmatized_text = None\n",
        "    try:\n",
        "        with zipfile.ZipFile('lem.zip', 'r') as archive:\n",
        "            data = archive.read(archive.namelist()[0])\n",
        "            lemmatized_text = [word.text for word in ET.fromstring(data).findall('chunk/sentence/tok/lex/base')]\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "    return lemmatized_text\n",
        "\n",
        "\n",
        "def tokenize(text):\n",
        "    tokens = re.split('\\W+', text)\n",
        "    text = [word for word in tokens]\n",
        "    return text\n",
        "\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    requester = Requester('241393@student.pwr.edu.pl')\n",
        "    lpmn_query = 'any2txt|morphoDita|dir|termopl2({\\\"mw\\\":false,\\\"sw\\\":\\\"/resources/termopl/termopl_sw.txt\\\",' \\\n",
        "                 '\\\"cp\\\":\\\"/resources/termopl/termopl_cp.txt\\\"}) '\n",
        "\n",
        "    string_ids = requester.upload_strings([text])\n",
        "    response = requester.process_query(lpmn_query, [string_id.text for string_id in string_ids])\n",
        "    requester.download_response(response[0], './no_stopwords.zip')\n",
        "\n",
        "    lemmatized_text_without_stopwords = None\n",
        "    try:\n",
        "        with zipfile.ZipFile('no_stopwords.zip', 'r') as archive:\n",
        "            with archive.open(archive.namelist()[0]) as data:\n",
        "                column_names = ['idx', 'ranking', 'output_phrase', 'original_phrase', 'c-value',\n",
        "                                'length', 'freq_s', 'freq_in', 'context']\n",
        "                df = pd.read_csv(data, sep='\\t', names=column_names)\n",
        "\n",
        "        lemmatized_text_without_stopwords = df['output_phrase'].tolist()\n",
        "    except IndexError as e:\n",
        "        print(e)\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        \n",
        "    return lemmatized_text_without_stopwords\n",
        "\n",
        "\n",
        "#TODO when we decide what how to preprocess text\n",
        "# now it is just copy-paste from online course\n",
        "def clean_text(text):\n",
        "    no_punctuation_text = remove_punctuation(text)\n",
        "    cleaned_text = lemmatize(no_punctuation_text)\n",
        "    return cleaned_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwPjKIVfPRCQ"
      },
      "source": [
        "# Took only 5 first elements to demonstrate the output\n",
        "df['lemmatized'] = df['content'][:5].apply(lambda x: lemmatize(x))\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1oLSenGPFEx"
      },
      "source": [
        "df['lemmatized_without_stopwords'] = df['content'][:5].apply(lambda x: remove_stopwords(x))\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZ7-2hMpVSxG",
        "tags": [
          "outputPrepend"
        ]
      },
      "source": [
        "df['clean_text'] = df['content'].apply(lambda x: clean_text(x))\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHbMIcgGt8xf"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df[['clean_text', 'uppercase%', 'exclamation_mark%', 'question_mark%', 'quotation_mark%', 'punctuation%',\n",
        "        'length', 'sentiment', 'positive_words%', 'negative_words%']], df['label'], test_size=0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5vWEUGPzpSa"
      },
      "source": [
        "X_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RpIZNAcSYI3"
      },
      "source": [
        "## Vectorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M29--NLvSgJ7"
      },
      "source": [
        "### N-gram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqQnNTC3ScdN"
      },
      "source": [
        "# range = (2, 2)\n",
        "\n",
        "# ngram_vect = CountVectorizer(ngram_range=range)\n",
        "# X_ngram = ngram_vect.fit_transform(X['content'])\n",
        "\n",
        "# X_ngram_df = pd.DataFrame(X_ngram.toarray())\n",
        "# X_ngram_df.columns = ngram_vect.get_feature_names()\n",
        "# X_ngram_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYny71hQSlGb"
      },
      "source": [
        "### TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1AM3pFYSk1-"
      },
      "source": [
        "clean_joined = df['clean_text'].apply(lambda x: ' '.join(x))\n",
        "X_train_clean_joined = X_train['clean_text'].apply(lambda x: ' '.join(x))\n",
        "X_test_clean_joined = X_test['clean_text'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "tfidf_vect = TfidfVectorizer(ngram_range=(1, 3))\n",
        "tfidf_vect_fit = tfidf_vect.fit(X_train_clean_joined)\n",
        "\n",
        "tfidf_train = tfidf_vect_fit.transform(X_train_clean_joined)\n",
        "tfidf_test = tfidf_vect_fit.transform(X_test_clean_joined)\n",
        "\n",
        "X_train_vect = pd.concat([X_train[\n",
        "                              ['uppercase%', 'exclamation_mark%', 'question_mark%', 'quotation_mark%', 'punctuation%',\n",
        "                               'length', 'sentiment', 'positive_words%', 'negative_words%']].reset_index(drop=True),\n",
        "                          pd.DataFrame(tfidf_train.toarray())], axis=1)\n",
        "\n",
        "X_test_vect = pd.concat([X_test[\n",
        "                             ['uppercase%', 'exclamation_mark%', 'question_mark%', 'quotation_mark%', 'punctuation%',\n",
        "                              'length', 'sentiment', 'positive_words%', 'negative_words%']].reset_index(drop=True),\n",
        "                         pd.DataFrame(tfidf_test.toarray())], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohqxF6_YRikd"
      },
      "source": [
        "# Saving training and testing sets\n",
        "X_train_vect.to_csv(f'{content_root}/X_train_tfidf.csv', index=False, header=True)\n",
        "X_test_vect.to_csv(f'{content_root}/X_test_tfidf.csv', index=False, header=True)\n",
        "y_train.to_csv(f'{content_root}/y_train_tfidf.csv', index=False, header=True)\n",
        "y_test.to_csv(f'{content_root}/y_test_tfidf.csv', index=False, header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ormFzUkN7Hpp"
      },
      "source": [
        "# Saving all the features (only for GridSearchCV)\n",
        "X_tfidf = tfidf_vect.fit_transform(clean_joined)\n",
        "X_tfidf_feat = pd.concat([df[['uppercase%', 'exclamation_mark%', 'question_mark%', 'quotation_mark%', 'punctuation%',\n",
        "                              'length', 'sentiment', 'positive_words%', 'negative_words%']].reset_index(drop=True),\n",
        "                          pd.DataFrame(X_tfidf.toarray())], axis=1)\n",
        "\n",
        "X_tfidf_feat.to_csv(tfidf_features_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpQ-Ho-ddM-O"
      },
      "source": [
        "# X_test_vect[0].toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJipDeh-8US-"
      },
      "source": [
        "# Loading features\n",
        "X_tfidf_feat = pd.read_csv(tfidf_features_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFJCT-KhnedH"
      },
      "source": [
        "# Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfcVBbR4Bjo3"
      },
      "source": [
        "rf = RandomForestClassifier(random_state=1410)\n",
        "param = {\n",
        "    'max_depth': [80, 90, 100, 110, None],\n",
        "    'max_features': [0.2, None],\n",
        "    'min_samples_leaf': [3, 4, 5],\n",
        "    'min_samples_split': [8, 10, 12],\n",
        "    'n_estimators': [100, 200, 300, 1000]\n",
        "}\n",
        "\n",
        "gs = GridSearchCV(rf, param, cv=5, n_jobs=-1, return_train_score=True)\n",
        "gs_fit = gs.fit(X_tfidf_feat, data['label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rw2jDsLrZ1pf"
      },
      "source": [
        "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False)[0:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cUrdk4NniCS"
      },
      "source": [
        "# Model nr 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDcT0PuXac4i"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-I33FR-nnJg"
      },
      "source": [
        "# Deep Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#read in clean text\n",
        "df = pd.read_csv('data/clean.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df['clean_text'], df['label'], test_size=0.25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1mEUfPj_Oq9"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "padding_length = len(max(X_train_seq, key=len))\n",
        "\n",
        "X_train_seq_pad = pad_sequences(X_train_seq, padding_length)\n",
        "X_test_seq_pad = pad_sequences(X_test_seq, padding_length)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oC7fIMjgzuUJ"
      },
      "source": [
        "X_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wMFQUxR4A_W"
      },
      "source": [
        "## RNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_seq_pad"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHU2UZnyeBZS"
      },
      "source": [
        "batch_size = 32\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(tokenizer.index_word)+1, 32))\n",
        "model.add(LSTM(64, dropout=0.3, recurrent_dropout=0.3, recurrent_initializer='glorot_uniform', return_sequences=True))\n",
        "model.add(LSTM(32, dropout=0.3, recurrent_dropout=0.3, recurrent_initializer='glorot_uniform'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JINiT4LXgl4o"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4d1AeMd49ig"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3cFAQbHkOrk"
      },
      "source": [
        "early_stopping = EarlyStopping(monitor='loss', patience=3)\n",
        "\n",
        "y_train_cat = to_categorical(y_train, 2)\n",
        "y_test_cat = to_categorical(y_test, 2)\n",
        "\n",
        "history = model.fit(X_train_seq_pad, y_train_cat, validation_data=(X_test_seq_pad, y_test_cat), batch_size=batch_size, epochs=10, callbacks=[early_stopping])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "### Prediction presentation"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wt2ew1mfoYuv"
      },
      "source": [
        "\n",
        "for numb in range(100, 140):\n",
        "    print('Treść wypowiedzi:')\n",
        "    print(X_test.iloc[numb])\n",
        "    print('Klasyfikacja: ', y_test.iloc[numb])\n",
        "    prediction = model.predict(np.array([X_test_seq[numb]]))\n",
        "    print('Predykcja: ', [round(prc, 2) for prc in prediction[0]])\n",
        "    print('================================================')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def rnn_text_classification(text):\n",
        "#     prediction = model.predict(np.array([X_test_seq[numb]]))\n",
        "#     prediction = [round(prc, 2) for prc in prediction[0]]\n",
        "    \n",
        "#     return prediction\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0vEYixp4OWQ"
      },
      "source": [
        "result = tf.argmax(model.predict_on_batch(tf.expand_dims(X_test_seq_pad[16], 0)), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "## Artificial Neural Network"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "padding_length = len(max(X_train_seq, key=len))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(padding_length, activation='relu'))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "# model.add(Dropout(0.25))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "# model.add(Dropout(0.25))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "# model.add(Dropout(0.25))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(2, activation='softmax'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='mse',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_seq_pad = pad_sequences(X_train_seq, padding_length)\n",
        "X_test_seq_pad = pad_sequences(X_test_seq, padding_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history = model.fit(X_train_seq_pad, y_train_cat, validation_data=(X_test_seq_pad, y_test_cat), batch_size=batch_size, epochs=10, callbacks=[early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "source": [
        "### Prediction presentation"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# np.array([X_test_seq[100]])\n",
        "# prediction = model.predict(np.array([X_test_seq[100]]))\n",
        "\n",
        "for numb in range(100, 140):\n",
        "    print('Treść wypowiedzi:')\n",
        "    print(X_test.iloc[numb])\n",
        "    print('Klasyfikacja: ', y_test.iloc[numb])\n",
        "    prediction = model.predict(np.array([X_test_seq_pad[numb]]))\n",
        "    print('Predykcja: ', [round(prc, 2) for prc in prediction[0]])\n",
        "    # print(X_test_seq_pad[numb])\n",
        "    print('================================================')\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8f79i215ns_O"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcxV7qHxees3"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qc7kl2ODnuk9"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}