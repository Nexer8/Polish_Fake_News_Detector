{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cX-nXlspqesI"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rvdXqfSKPXc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef6b1be0-dedd-4862-ebc6-1ad1d63684c3"
      },
      "source": [
        "!pip install -i https://pypi.clarin-pl.eu lpmn_client"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxS2kfBwqdar",
        "outputId": "e7db9d53-063d-4f88-e76b-a00112b9509c"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "import re, string\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Dense, Embedding, LSTM, Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.losses import sparse_categorical_crossentropy\n",
        "from lpmn_client.src.requester import Requester\n",
        "import zipfile\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import xml.etree.ElementTree as ET\n",
        "import numbers\n",
        "import decimal\n",
        "import tensorflow as tf"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8c1FijT1mrnh"
      },
      "source": [
        "# Data loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dy75juyZrT2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "97eb581f-3abd-4dfc-b270-cb8ab6da4b27"
      },
      "source": [
        "data_path = 'data/citations.csv'\n",
        "tfidf_features_path = 'data/tfidf_all_features.csv'\n",
        "\n",
        "pd.set_option('display.max_rows', 10)\n",
        "pd.set_option('display.max_colwidth', 120)\n",
        "\n",
        "df = pd.read_csv(data_path)\n",
        "df = df.dropna()\n",
        "df = df.reset_index(drop=True)\n",
        "# df.info()\n",
        "\n",
        "classes_names = {0: 'Fałsz', 1: 'Prawda', 2: \"Manipulacja\", 3: \"Nieweryfikowalne\"}\n",
        "df['label'].replace({'Fałsz': 0, 'Prawda': 1, 'Manipulacja': 2, 'Nieweryfikowalne': 3}, inplace=True)\n",
        "df = df[(df['label'] == 0) | (df['label'] == 1)]\n",
        "# X.head()\n",
        "# y.head(10)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73PqDGDXRSJB"
      },
      "source": [
        "# Feature creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEHv3t1ARYQP"
      },
      "source": [
        "def count_uppercase_letters(text):\n",
        "    count = sum([1 for char in text if char.isupper()])\n",
        "    return (count / (len(text) - text.count(' '))) * 100\n",
        "\n",
        "\n",
        "def count_exclamation_marks(text):\n",
        "    count = text.count('!')\n",
        "    return (count / (len(text) - text.count(' '))) * 100\n",
        "\n",
        "\n",
        "def count_question_marks(text):\n",
        "    count = text.count('?')\n",
        "    return (count / (len(text) - text.count(' '))) * 100\n",
        "\n",
        "\n",
        "def count_quotation_marks(text):\n",
        "    count = text.count('\"')\n",
        "    return (count / (len(text) - text.count(' '))) * 100\n",
        "\n",
        "\n",
        "def count_punctuation(text):\n",
        "    count = sum([1 for char in text if char in string.punctuation])\n",
        "    return (count / (len(text) - text.count(' '))) * 100\n",
        "\n",
        "\n",
        "def count_text_length(text):\n",
        "    return len(text) - text.count(' ')\n",
        "\n",
        "\n",
        "def get_sentiment(text):\n",
        "    requester = Requester('241393@student.pwr.edu.pl')\n",
        "    lpmn_query = 'any2txt|wcrft2|wsd|ccl_emo({\"lang\":\"polish\"})|ccl_emo_stats({' \\\n",
        "                 '\"lang\":\"polish\", \"split_paragraphs\": false})'\n",
        "\n",
        "    string_ids = requester.upload_strings([text])\n",
        "    response = requester.process_query(lpmn_query, [string_id.text for string_id in string_ids])\n",
        "    requester.download_response(response[0], './sentiment.zip')\n",
        "\n",
        "    try:\n",
        "        with zipfile.ZipFile('sentiment.zip', 'r') as archive:\n",
        "            with archive.open(archive.namelist()[0]) as data:\n",
        "                df = pd.read_csv(data, sep=';')\n",
        "\n",
        "        sentiment_value = sum([int(entry) for entry in df['Polarity'].values if\n",
        "                               (type(entry) == str and entry.isnumeric()) or isinstance(entry, (int, float, complex))])\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        sentiment_value = 0\n",
        "\n",
        "    return sentiment_value\n",
        "\n",
        "\n",
        "def count_positive_words():\n",
        "    try:\n",
        "        with zipfile.ZipFile('sentiment.zip', 'r') as archive:\n",
        "            with archive.open(archive.namelist()[0]) as data:\n",
        "                df = pd.read_csv(data, sep=';')\n",
        "\n",
        "        positive_words = (sum([1 for entry in df['Polarity'].values if\n",
        "                               (type(entry) == str and entry.isnumeric() or isinstance(entry,\n",
        "                                                                                       (int, float, complex))) and int(\n",
        "                                   entry) > 0]) / len(df['Polarity'])) * 100\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        positive_words = 0\n",
        "\n",
        "    return positive_words\n",
        "\n",
        "\n",
        "def count_negative_words():\n",
        "    try:\n",
        "        with zipfile.ZipFile('sentiment.zip', 'r') as archive:\n",
        "            with archive.open(archive.namelist()[0]) as data:\n",
        "                df = pd.read_csv(data, sep=';')\n",
        "\n",
        "        negative_words = (sum([1 for entry in df['Polarity'].values if\n",
        "                               (type(entry) == str and entry.isnumeric() or isinstance(entry,\n",
        "                                                                                       (int, float, complex))) and int(\n",
        "                                   entry) < 0]) / len(df['Polarity'])) * 100\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        negative_words = 0\n",
        "\n",
        "    return negative_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JWdvWr12hZa",
        "outputId": "f7b44809-da5d-4c0b-88d2-645237901cd4"
      },
      "source": [
        "# Run only if there is a need to regenerate all the features. Otherwise, go to Loading features.\n",
        "df['uppercase%'] = df['content'].apply(lambda x: count_uppercase_letters(x))\n",
        "df['exclamation_mark%'] = df['content'].apply(lambda x: count_exclamation_marks(x))\n",
        "df['question_mark%'] = df['content'].apply(lambda x: count_question_marks(x))\n",
        "df['quotation_mark%'] = df['content'].apply(lambda x: count_quotation_marks(x))\n",
        "df['punctuation%'] = df['content'].apply(lambda x: count_punctuation(x))\n",
        "df['length'] = df['content'].apply(lambda x: count_text_length(x))\n",
        "\n",
        "rows_list = []\n",
        "for index, row in df.iterrows():\n",
        "    dictionary = {'sentiment': get_sentiment(df.at[index, 'content']),\n",
        "                  'positive_words%': count_positive_words(),\n",
        "                  'negative_words%': count_negative_words()}\n",
        "\n",
        "    rows_list.append(dictionary)\n",
        "    print(f'Index: {index}')\n",
        "\n",
        "df = pd.concat([df.reset_index(drop=True), pd.DataFrame(rows_list).reset_index(drop=True)], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ps_WndVgf5WC"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXFt-ey6mqXj"
      },
      "source": [
        "df.to_csv(tfidf_features_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iOqXFSDmxdw"
      },
      "source": [
        "# Text preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ah8YXWTVZ0A7"
      },
      "source": [
        "def remove_punctuation(text):\n",
        "    no_punctuation_text = \"\".join([char for char in text if char not in string.punctuation])\n",
        "    return no_punctuation_text\n",
        "\n",
        "\n",
        "def lemmatize(text):\n",
        "    requester = Requester('241393@student.pwr.edu.pl')\n",
        "    lpmn_query = 'any2txt|wcrft2({\"guesser\":false, \"morfeusz2\":true})'\n",
        "\n",
        "    string_ids = requester.upload_strings([text])\n",
        "    response = requester.process_query(lpmn_query, [id.text for id in string_ids])\n",
        "    requester.download_response(response[0], './lem.zip')\n",
        "\n",
        "    lemmatized_text = None\n",
        "    try:\n",
        "        with zipfile.ZipFile('lem.zip', 'r') as archive:\n",
        "            data = archive.read(archive.namelist()[0])\n",
        "            lemmatized_text = [word.text for word in ET.fromstring(data).findall('chunk/sentence/tok/lex/base')]\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "    return lemmatized_text\n",
        "\n",
        "\n",
        "def tokenize(text):\n",
        "    tokens = re.split('\\W+', text)\n",
        "    text = [word for word in tokens]\n",
        "    return text\n",
        "\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    requester = Requester('241393@student.pwr.edu.pl')\n",
        "    lpmn_query = 'any2txt|morphoDita|dir|termopl2({\\\"mw\\\":false,\\\"sw\\\":\\\"/resources/termopl/termopl_sw.txt\\\",' \\\n",
        "                 '\\\"cp\\\":\\\"/resources/termopl/termopl_cp.txt\\\"}) '\n",
        "\n",
        "    string_ids = requester.upload_strings([text])\n",
        "    response = requester.process_query(lpmn_query, [string_id.text for string_id in string_ids])\n",
        "    requester.download_response(response[0], './no_stopwords.zip')\n",
        "\n",
        "    lemmatized_text_without_stopwords = None\n",
        "    try:\n",
        "        with zipfile.ZipFile('no_stopwords.zip', 'r') as archive:\n",
        "            with archive.open(archive.namelist()[0]) as data:\n",
        "                column_names = ['idx', 'ranking', 'output_phrase', 'original_phrase', 'c-value',\n",
        "                                'length', 'freq_s', 'freq_in', 'context']\n",
        "                df = pd.read_csv(data, sep='\\t', names=column_names)\n",
        "\n",
        "        lemmatized_text_without_stopwords = df['output_phrase'].tolist()\n",
        "    except IndexError as e:\n",
        "        print(e)\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        \n",
        "    return lemmatized_text_without_stopwords\n",
        "\n",
        "\n",
        "#TODO when we decide what how to preprocess text\n",
        "# now it is just copy-paste from online course\n",
        "def clean_text(text):\n",
        "    no_punctuation_text = remove_punctuation(text)\n",
        "    cleaned_text = lemmatize(no_punctuation_text)\n",
        "    return cleaned_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwPjKIVfPRCQ"
      },
      "source": [
        "# Took only 5 first elements to demonstrate the output\n",
        "df['lemmatized'] = df['content'][:5].apply(lambda x: lemmatize(x))\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1oLSenGPFEx"
      },
      "source": [
        "df['lemmatized_without_stopwords'] = df['content'][:5].apply(lambda x: remove_stopwords(x))\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZ7-2hMpVSxG",
        "tags": [
          "outputPrepend"
        ]
      },
      "source": [
        "df['clean_text'] = df['content'].apply(lambda x: clean_text(x))\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHbMIcgGt8xf"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df[['clean_text', 'uppercase%', 'exclamation_mark%', 'question_mark%', 'quotation_mark%', 'punctuation%',\n",
        "        'length', 'sentiment', 'positive_words%', 'negative_words%']], df['label'], test_size=0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5vWEUGPzpSa"
      },
      "source": [
        "X_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RpIZNAcSYI3"
      },
      "source": [
        "## Vectorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M29--NLvSgJ7"
      },
      "source": [
        "### N-gram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqQnNTC3ScdN"
      },
      "source": [
        "# range = (2, 2)\n",
        "\n",
        "# ngram_vect = CountVectorizer(ngram_range=range)\n",
        "# X_ngram = ngram_vect.fit_transform(X['content'])\n",
        "\n",
        "# X_ngram_df = pd.DataFrame(X_ngram.toarray())\n",
        "# X_ngram_df.columns = ngram_vect.get_feature_names()\n",
        "# X_ngram_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYny71hQSlGb"
      },
      "source": [
        "### TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1AM3pFYSk1-"
      },
      "source": [
        "clean_joined = df['clean_text'].apply(lambda x: ' '.join(x))\n",
        "X_train_clean_joined = X_train['clean_text'].apply(lambda x: ' '.join(x))\n",
        "X_test_clean_joined = X_test['clean_text'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "tfidf_vect = TfidfVectorizer(ngram_range=(1, 3))\n",
        "tfidf_vect_fit = tfidf_vect.fit(X_train_clean_joined)\n",
        "\n",
        "tfidf_train = tfidf_vect_fit.transform(X_train_clean_joined)\n",
        "tfidf_test = tfidf_vect_fit.transform(X_test_clean_joined)\n",
        "\n",
        "X_train_vect = pd.concat([X_train[\n",
        "                              ['uppercase%', 'exclamation_mark%', 'question_mark%', 'quotation_mark%', 'punctuation%',\n",
        "                               'length', 'sentiment', 'positive_words%', 'negative_words%']].reset_index(drop=True),\n",
        "                          pd.DataFrame(tfidf_train.toarray())], axis=1)\n",
        "\n",
        "X_test_vect = pd.concat([X_test[\n",
        "                             ['uppercase%', 'exclamation_mark%', 'question_mark%', 'quotation_mark%', 'punctuation%',\n",
        "                              'length', 'sentiment', 'positive_words%', 'negative_words%']].reset_index(drop=True),\n",
        "                         pd.DataFrame(tfidf_test.toarray())], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohqxF6_YRikd"
      },
      "source": [
        "# Saving training and testing sets\n",
        "X_train_vect.to_csv(f'{content_root}/X_train_tfidf.csv', index=False, header=True)\n",
        "X_test_vect.to_csv(f'{content_root}/X_test_tfidf.csv', index=False, header=True)\n",
        "y_train.to_csv(f'{content_root}/y_train_tfidf.csv', index=False, header=True)\n",
        "y_test.to_csv(f'{content_root}/y_test_tfidf.csv', index=False, header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ormFzUkN7Hpp"
      },
      "source": [
        "# Saving all the features (only for GridSearchCV)\n",
        "X_tfidf = tfidf_vect.fit_transform(clean_joined)\n",
        "X_tfidf_feat = pd.concat([df[['uppercase%', 'exclamation_mark%', 'question_mark%', 'quotation_mark%', 'punctuation%',\n",
        "                              'length', 'sentiment', 'positive_words%', 'negative_words%']].reset_index(drop=True),\n",
        "                          pd.DataFrame(X_tfidf.toarray())], axis=1)\n",
        "\n",
        "X_tfidf_feat.to_csv(tfidf_features_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpQ-Ho-ddM-O"
      },
      "source": [
        "# X_test_vect[0].toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJipDeh-8US-"
      },
      "source": [
        "# Loading features\n",
        "X_tfidf_feat = pd.read_csv(tfidf_features_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFJCT-KhnedH"
      },
      "source": [
        "# Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfcVBbR4Bjo3"
      },
      "source": [
        "rf = RandomForestClassifier(random_state=1410)\n",
        "param = {\n",
        "    'max_depth': [80, 90, 100, 110, None],\n",
        "    'max_features': [0.2, None],\n",
        "    'min_samples_leaf': [3, 4, 5],\n",
        "    'min_samples_split': [8, 10, 12],\n",
        "    'n_estimators': [100, 200, 300, 1000]\n",
        "}\n",
        "\n",
        "gs = GridSearchCV(rf, param, cv=5, n_jobs=-1, return_train_score=True)\n",
        "gs_fit = gs.fit(X_tfidf_feat, data['label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rw2jDsLrZ1pf"
      },
      "source": [
        "pd.DataFrame(gs_fit.cv_results_).sort_values('mean_test_score', ascending=False)[0:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cUrdk4NniCS"
      },
      "source": [
        "# Model nr 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDcT0PuXac4i"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-I33FR-nnJg"
      },
      "source": [
        "# Deep Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "#read in clean text\n",
        "df = pd.read_csv('data/clean.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df['clean_text'], df['label'], test_size=0.25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1mEUfPj_Oq9"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "padding_length = len(max(X_train_seq, key=len))\n",
        "\n",
        "X_train_seq_pad = pad_sequences(X_train_seq, padding_length)\n",
        "X_test_seq_pad = pad_sequences(X_test_seq, padding_length)\n",
        "\n"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oC7fIMjgzuUJ"
      },
      "source": [
        "X_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wMFQUxR4A_W"
      },
      "source": [
        "## RNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_seq_pad"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHU2UZnyeBZS"
      },
      "source": [
        "batch_size = 32\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(tokenizer.index_word)+1, 32))\n",
        "model.add(LSTM(64, dropout=0.3, recurrent_dropout=0.3, recurrent_initializer='glorot_uniform', return_sequences=True))\n",
        "model.add(LSTM(32, dropout=0.3, recurrent_dropout=0.3, recurrent_initializer='glorot_uniform'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "model.summary()\n"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_13\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_7 (Embedding)      (None, None, 32)          239808    \n_________________________________________________________________\nlstm_11 (LSTM)               (None, None, 64)          24832     \n_________________________________________________________________\nlstm_12 (LSTM)               (None, 32)                12416     \n_________________________________________________________________\ndense_34 (Dense)             (None, 64)                2112      \n_________________________________________________________________\ndense_35 (Dense)             (None, 2)                 130       \n=================================================================\nTotal params: 279,298\nTrainable params: 279,298\nNon-trainable params: 0\n_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JINiT4LXgl4o"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4d1AeMd49ig"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3cFAQbHkOrk"
      },
      "source": [
        "early_stopping = EarlyStopping(monitor='loss', patience=3)\n",
        "\n",
        "y_train_cat = to_categorical(y_train, 2)\n",
        "y_test_cat = to_categorical(y_test, 2)\n",
        "\n",
        "history = model.fit(X_train_seq_pad, y_train_cat, validation_data=(X_test_seq_pad, y_test_cat), batch_size=batch_size, epochs=10, callbacks=[early_stopping])"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "84/84 [==============================] - 36s 330ms/step - loss: 0.6164 - accuracy: 0.7213 - val_loss: 0.5969 - val_accuracy: 0.7167\n",
            "Epoch 2/10\n",
            "84/84 [==============================] - 26s 314ms/step - loss: 0.5890 - accuracy: 0.7263 - val_loss: 0.5992 - val_accuracy: 0.7167\n",
            "Epoch 3/10\n",
            "84/84 [==============================] - 28s 330ms/step - loss: 0.5763 - accuracy: 0.7166 - val_loss: 0.5958 - val_accuracy: 0.7122\n",
            "Epoch 4/10\n",
            "84/84 [==============================] - 26s 313ms/step - loss: 0.3876 - accuracy: 0.8271 - val_loss: 0.7699 - val_accuracy: 0.6920\n",
            "Epoch 5/10\n",
            "84/84 [==============================] - 26s 307ms/step - loss: 0.1977 - accuracy: 0.9199 - val_loss: 0.9658 - val_accuracy: 0.6708\n",
            "Epoch 6/10\n",
            "84/84 [==============================] - 27s 324ms/step - loss: 0.1048 - accuracy: 0.9643 - val_loss: 1.2464 - val_accuracy: 0.6473\n",
            "Epoch 7/10\n",
            "84/84 [==============================] - 21s 252ms/step - loss: 0.0643 - accuracy: 0.9793 - val_loss: 1.5498 - val_accuracy: 0.6495\n",
            "Epoch 8/10\n",
            "84/84 [==============================] - 22s 257ms/step - loss: 0.0340 - accuracy: 0.9847 - val_loss: 1.6834 - val_accuracy: 0.6551\n",
            "Epoch 9/10\n",
            "84/84 [==============================] - 21s 247ms/step - loss: 0.0327 - accuracy: 0.9900 - val_loss: 1.8297 - val_accuracy: 0.6585\n",
            "Epoch 10/10\n",
            "84/84 [==============================] - 20s 237ms/step - loss: 0.0151 - accuracy: 0.9939 - val_loss: 2.1215 - val_accuracy: 0.6271\n"
          ]
        }
      ]
    },
    {
      "source": [
        "### Prediction presentation"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wt2ew1mfoYuv"
      },
      "source": [
        "\n",
        "for numb in range(100, 140):\n",
        "    print('Treść wypowiedzi:')\n",
        "    print(X_test.iloc[numb])\n",
        "    print('Klasyfikacja: ', y_test.iloc[numb])\n",
        "    prediction = model.predict(np.array([X_test_seq[numb]]))\n",
        "    print('Predykcja: ', [round(prc, 2) for prc in prediction[0]])\n",
        "    print('================================================')\n"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treść wypowiedzi:\n",
            "['i', 'co', 'by', 'być', 'tutaj', 'nie', 'powiedzieć', 'złe', 'bo', 'zawsze', 'krytyk', 'się', 'znajda', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'to', 'Polska', 'w', 'moment', 'start', 'w', '89', 'rok', 'była', 'na', 'poziom', 'Białoruś', 'i', 'Ukraina', 'ukraina', 'czyli', 'przeciętny', 'Polak', 'wytwarzać', 'tyle', 'to', 'dochód', 'narodowy', 'ile', 'Białorusin', 'i', 'Ukrainiec', 'tam', 'minimalny', 'różnica', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'dolar', 'na', 'głowa', 'no', 'i', 'po', '25', 'lato', 'być', 'w', 'tym', 'miejsce', 'że', 'my', 'być', 'trzy', 'trzy', 'trzy', 'trzy', 'trzy', 'trzy', 'trzy', 'trzy', 'trzy', 'trzy', 'trzy', 'trzy', 'raz', 'zamożny', 'od', 'Białorusin', 'i', 'Ukrainiec']\n",
            "Klasyfikacja:  0\n",
            "Predykcja:  [0.99, 0.01]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['w', 'rok', '2015', 'na', '35', 'kraj', 'w', 'Europa', '34', 'miejsce', 'zajmować', 'ochrona', 'zdrowie', 'w', 'Polska']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [0.0, 1.0]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['jeden', 'z', 'moi', 'mój', 'konkurent', 'Rafał', 'Trzaskowski', '–', 'przyp', 'demagog', 'głosować', 'przeciwko', 'ustawa', 'obniżający', 'wiek', 'emerytalny', 'kiedy', 'być', 'poseł', 'przeciwko', 'moja', 'ustawa']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [0.02, 0.98]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['pani', 'poseł', 'mówić', 'że', 'sum', 'środek', 'zgromadzić', 'na', 'rezerwa', 'ogólny', 'budżet', 'państwo', 'jakoś', 'kosmicznie', 'wzrosły', 'on', 'wzrosły', 'o', 'mało', 'dużo', 'więcej', '15', '–', '20', '…', 'w', 'stosunek', 'do', 'zeszły', 'rok', 'dzisiaj', 'ta', 'sum', 'wynosić', 'oko', '250', 'milion', 'złoty']\n",
            "Klasyfikacja:  0\n",
            "Predykcja:  [0.0, 1.0]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['średnio', 'dzisiaj', 'nasze', 'blok', 'który', 'były', 'budować', 'kilkanaście', 'kilkanaście', 'kilkanaście', 'kilkanaście', 'kilkanaście', 'kilkanaście', 'kilkanaście', 'kilkanaście', 'kilkanaście', 'kilkanaście', 'kilkanaście', 'kilkanaście', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'lato', 'temu', 'na', 'jeden', 'megawatogodzina', 'energia', 'emitować', 'oko', '950', 'kilogram', 'CO2', 'nowa', 'inwestycja', 'w', 'Kozienice', 'który', 'być', 'ukończyć', 'w', 'przyszły', 'rok', 'to', 'być', '730', 'kgmegawatogodzinę']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [0.0, 1.0]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['z', 'początek', '2021', 'rok', 'NFZ', 'całkowicie', 'znieść', 'limit', 'w', 'zakres', 'świadczenie', 'psychiatryczny', 'dla', 'dziecko', 'i', 'młodzież']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [0.0, 1.0]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['w', 'mała', 'miasto', 'niemiecki', '200', '300', 'tysięczny', 'być', 'metro']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [0.98, 0.02]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['złożyć', 'być', 'projekt', 'który', 'nie', 'tylko', 'zakładać', 'zrównać', 'świadczenie', 'oba', 'oba', 'oba', 'oba', 'oba', 'oba', 'oba', 'oba', 'oba', 'oba', 'oba', 'oba', 'oba', 'oba', 'oba', 'oba', 'oba', 'oba', 'oba', 'oba', 'oba', 'oba', 'grupa', 'do', 'poziom', '1477', 'złoty', 'ale', 'również', 'zajmować', 'się', 'zasiłek', 'pielęgnacyjny', 'który', 'wynosić', 'obecnie', '153', 'złoty', '…', 'PiS', 'my', 'ten', 'projekt', 'zamrozić']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [1.0, 0.0]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['Kampania', 'kampania', '„', 'Krak', 'to', 'stan', 'umysł', '”', 'za', 'który', 'miasto', 'w', 'ubiegły', 'rokuzapłaciło', '200', 'tys', 'złoty', 'billboard', 'i', 'ogłoszenie', 'prasowy', 'w', '5', 'polski', 'miasto']\n",
            "Klasyfikacja:  0\n",
            "Predykcja:  [0.11, 0.89]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['już', 'nie', 'mówić', 'nawet', 'o', 'Stany', 'zjednoczyć', 'gdzie', 'sześć', 'sześć', 'sześć', 'sześć', 'sześć', 'sześć', 'sześć', 'sześć', 'sześć', 'sześć', 'sześć', 'sześć', 'raz', 'dużo', 'więcej', 'pieniądz', 'być', 'przekazywać', 'na', 'onkologia', 'nie', 'mówić', 'nawet', 'o', 'Francja', 'i', 'wielki', 'Brytania', 'brytania', 'czyli', 'kraj', 'unia', 'gdzie', 'się', 'przeznaczać', 'trzy', 'trzy', 'trzy', 'trzy', 'trzy', 'trzy', 'trzy', 'trzy', 'trzy', 'trzy', 'trzy', 'trzy', 'raz', 'dużo', 'więcej', 'pieniądz', 'ale', 'wystarczyć', 'powiedzieć', 'o', 'Czech', 'gdzie', 'się', 'przeznaczać', 'dwa', 'dwa', 'dwa', 'dwa', 'dwa', 'dwa', 'dwa', 'dwa', 'dwa', 'raz', 'pieniądz', 'na', 'onkologia']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [0.0, 1.0]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['z', 'ten', 'minione', '8', 'lato', '…', 'Polska', 'była', 'jedyna', 'kraj', 'w', 'cały', 'unia', 'europejski', 'który', 'nie', 'miał', 'okres', 'spadek', 'PKB', 'tylko', 'cały', 'czas', 'u', 'my', 'wzrastać']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [0.95, 0.05]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['maksymalnie', 'w', 'nasz', 'strategia', 'przewidywać', 'się', '6000', 'megawat', 'pozyskiwać', 'z', 'energia', 'jądrowy']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [0.0, 1.0]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['cały', 'budżet', 'Warszawa', 'warszawa', 'wynosić', 'oko', '13', 'miliard', 'rocznie']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [0.02, 0.98]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['tylko', 'platforma', 'mój', 'prawie', '35', 'kobieta', '…', 'żaden', 'inny', 'partia', 'się', 'nawet', 'nie', 'zbliżać', 'do', 'to']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [0.73, 0.27]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['zarówno', 'minister', 'polski', 'rząd', 'ale', 'także', 'prezydent', 'Andrzej', 'Duda', 'duda', 'rozpoczynać', 'taka', 'kampania', 'gospodarczy', 'współpraca', 'z', 'ten', 'kraj', 'do', 'który', 'od', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'lato', 'nikt', 'z', 'polski', 'władza', 'nie', 'jeździć', 'czyli', 'to', 'mama', 'Azja', 'mama', 'Chiny', 'mama', 'Afryka']\n",
            "Klasyfikacja:  0\n",
            "Predykcja:  [0.0, 1.0]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['Warszawa', 'warszawa', '…', 'to', 'być', '…', 'najbardziej', 'zadłużyć', 'gmina', 'w', 'Polska']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [0.97, 0.03]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['480', 'milion', 'złoty', 'wydawać', 'obecnie', 'na', 'komunikacja', 'miejski']\n",
            "Klasyfikacja:  0\n",
            "Predykcja:  [0.03, 0.97]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['rząd', 'deklarować', 'że', 'w', 'marzec', 'przyjąć', 'pierwsza', 'grupa', 'sto', 'sto', 'sto', 'sto', 'sto', 'sto', 'sto', 'sto', 'sto', 'sto', 'sto', 'sto', 'sto', 'sto', 'sto', 'sto', 'sto', 'sto', 'sto', 'sto', 'sto', 'sto', 'sto', 'uchodźca', 'zostać', 'wysłać', 'oficer', 'łącznik', 'do', 'Grecja', 'żeby', 'weryfikować', 'podobno', 'zweryfikować', 'pierwsza', '67', 'osoba']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [1.0, 0.0]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['żyć', 'w', 'państwo', 'który', 'wysyłać', '100', '000', 'kontrola', 'podatkowy', 'rocznie', 'z', 'który', 'tylko', '⅕', 'dawać', 'jakiś', 'efekt']\n",
            "Klasyfikacja:  0\n",
            "Predykcja:  [0.99, 0.01]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['uważać', 'że', 'należeć', 'wyprowadzić', 'religia', 'z', 'szkoła', 'a', 'te', '15', 'miliard', 'spożytkować', 'na', 'coś', 'lepsze']\n",
            "Klasyfikacja:  0\n",
            "Predykcja:  [0.99, 0.01]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['według', 'raport', '„', 'praca', 'i', 'przedsiębiorczość', 'kobieta', 'potencjał', 'do', 'wykorzystanie', 'w', 'Polska', '”', 'wskaźnik', 'aktywność', 'zawodowy', 'kobieta', 'w', 'Polska', 'wynosić', 'obecnie', '614', 'oznaczać', 'to', 'że', 'aż', '4', 'na', '10', 'Polek', 'w', 'wiek', 'produkcyjny', 'nie', 'pracować']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [0.0, 1.0]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['w', 'test', 'Pisa', 'z', 'matematyka', 'być', 'wysoce', 'wysoko', 'niż', 'Finlandia']\n",
            "Klasyfikacja:  0\n",
            "Predykcja:  [1.0, 0.0]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['szkolnictwo', 'zawodowy', 'co', 'wynikać', '…', 'z', 'raport', 'wysoki', 'izba', 'kontrola', 'nie', 'być', 'przystosować', 'do', 'rynek', 'praca']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [0.0, 1.0]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['na', 'sam', 'odsetek', 'od', 'dług', 'miasto', 'wydawać', 'rocznie', '35', 'milion', 'złoty']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [0.79, 0.21]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['nie', 'być', 'to', 'wina', 'nadzór', 'finansowy', 'nadzór', 'finansowy', 'dopiero', 'w', 'październik', '2013', 'rok', 'przyjąć', 'trzeba', 'być', 'zrobić', 'bardzo', 'dokładny', 'audyt', 'i', 'sprawdzić', 'co', 'się', 'dzieje', 'żeby', 'można', 'być', 'potem', 'postawić', 'ewentualnie', 'w', 'stan', 'upadłość']\n",
            "Klasyfikacja:  0\n",
            "Predykcja:  [0.0, 1.0]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['Sam', 'ustawa', 'o', 'media', 'medium', 'publiczny', 'zakładać', 'już', 'równy', 'stosunek', 'do', 'uczestnik', 'dyskurs', 'publiczny', 'że', 'to', 'być', 'obowiązek', 'media', 'medium', 'publiczny']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [0.48, 0.52]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['Paweł', 'Wojtunik', 'ależ', 'sejm', 'nie', 'być', 'opisać', 'nigdzie', 'w', 'prawie', 'jako', 'instytucja', 'do', 'który', 'nie', 'wolno', 'wejść', 'na', 'przeszukanie', 'być', 'jeden', 'podstawowy', 'zasada', 'przy', 'przeszukanie', 'instytucja', 'państwowy', 'a', 'taka', 'być', 'sejm', 'należeć', 'o', 'zamiar', 'to', 'być', 'równoznaczny', 'z', 'rozpoczęcie', 'przeszukanie', 'o', 'zamiar', 'przy', 'rozpoczęcie', 'przeszukanie', 'zawiadomić', 'kierownik', 'ten', 'instytucja', 'dlatego', 'że', 'ten', 'kierownik', '…', 'Monika', 'Olejnik', 'właśnie', 'o', 'tym', 'mówięPaweł', 'Wojtunik', 'dlatego', 'że', 'ta', 'osoba', 'mój', 'prawo', 'wyznaczyć', 'pracownik', 'do', 'udział', 'w', 'tym', 'przeszukanie']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [0.0, 1.0]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['a', 'co', 'mama', 'w', 'ustawa', 'który', 'zostać', 'dziś', 'w', 'noc', 'przegłosować', 'otwarty', 'zostać', 'ścieżek', 'że', 'już', 'nie', 'trzeba', 'być', 'prowadzić', 'konsultacja', 'społeczny', '–', 'ani', 'z', 'samorząd', 'lokalny', 'ani', 'z', 'prezydent', 'miast', 'ani', 'z', 'związek', 'zawodowy', 'a', 'być', 'można', 'na', 'podstawa', 'ustawa', 'podjąć', 'decyzja', 'o', 'likwidacja', 'kopalnia']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [0.0, 1.0]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['dwa', 'dwa', 'dwa', 'dwa', 'dwa', 'dwa', 'sędzia', 'wybrana', 'w', 'grudzień', 'orzekać', 'być', 'w', 'skład', 'TK']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [0.73, 0.27]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['chiński', 'produkcja', 'za', 'trzy', 'trzy', 'trzy', 'trzy', 'trzy', 'trzy', 'trzy', 'trzy', 'trzy', 'trzy', 'trzy', 'trzy', 'kwartał', 'to', '26', 'miliard', 'ton', 'węgiel']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [0.07, 0.93]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['w', 'sprawa', 'budżetowy', 'być', 'to', 'o', 'tyle', 'istotny', 'że', 'przyjęcie', 'perspektywa', 'finansowy', 'wymagać', 'zgoda', 'z', 'strona', 'parlament', 'europejski']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [0.0, 1.0]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['PiS', 'obiecać', 'budowa', 'tani', 'mieszkanie', 'na', 'wynajem', 'w', 'rama', 'mieszkanie', '”', '–', 'nie', 'zrobić']\n",
            "Klasyfikacja:  0\n",
            "Predykcja:  [0.0, 1.0]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['w', 'ranking', 'miast', 'wojewódzki', 'Łódź', 'łódź', 'być', 'druga', 'od', 'koniec', 'miasto', 'pod', 'względem', 'wielkość', 'bezrobocie', '127', 'bezrobocie', 'przed', 'Białystok', '139', 'dla', 'przykład', 'w', 'Poznań', 'stopa', 'bezrobocie', 'wynosić', '41', 'w', 'Warszawa', 'warszawa', '48', 'w', 'Wrocław', '56', 'w', 'Krak', '61', 'a', 'w', 'gdański', '69']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [0.04, 0.96]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['w', 'Wrocław', 'na', '1000', 'mieszkaniec', 'przypadać', 'aż', '632', 'samochód']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [0.93, 0.07]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['podpisać', 'ten', 'decyzja', 'reprywatyzacyjny', 'kamienica', 'przy', 'ulica', 'Noakowski', '16', 'urzędnik', 'prezydent', 'Lech', 'Kaczyński']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [0.0, 1.0]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['nie', 'zostać', 'ruszyć', 'procedura', 'na', 'etap', 'postępowanie', 'przygotowawczy', '…', 'być', 'co', 'do', 'zasada', 'inkwizycyjny']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [0.35, 0.65]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['jeśli', 'chodzić', 'o', 'obciążenie', 'podatkowy', 'zarówno', 'w', 'postać', 'podatek', 'pośredni', 'jak', 'i', 'bezpośredni', 'Polska', 'na', 'tło', 'inny', 'kraj', 'unia', 'europejski', 'być', 'średniak', 'znajdować', 'znajdywać', 'się', 'gdzieś', 'tak', 'pośrodku', 'stawek']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [0.01, 0.99]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['poprzeć', 'być', 'PiS', 'pani', 'KidawęBłońską', 'na', 'Marszałek', 'marszałek', 'sejm']\n",
            "Klasyfikacja:  0\n",
            "Predykcja:  [0.02, 0.98]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['Polska', 'posiadać', 'jeden', 'z', 'niski', 'w', 'Europa', 'współczynnik', 'możliwy', 'mobilizacja', 'rezerwa']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [0.99, 0.01]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['przypominać', 'że', 'to', 'być', 'mocarstwo', 'Rosja', 'który', 'mój', 'doktryna', 'na', 'prewencyjny', 'użycie', 'taki', 'broń', 'atomowy']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [0.14, 0.86]\n",
            "================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def rnn_text_classification(text):\n",
        "#     prediction = model.predict(np.array([X_test_seq[numb]]))\n",
        "#     prediction = [round(prc, 2) for prc in prediction[0]]\n",
        "    \n",
        "#     return prediction\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0vEYixp4OWQ"
      },
      "source": [
        "result = tf.argmax(model.predict_on_batch(tf.expand_dims(X_test_seq_pad[16], 0)), axis=1)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "source": [
        "## Artificial Neural Network"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [],
      "source": [
        "padding_length = len(max(X_train_seq, key=len))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(padding_length, activation='relu'))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "# model.add(Dropout(0.25))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "# model.add(Dropout(0.25))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "# model.add(Dropout(0.25))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(2, activation='softmax'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='mse',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0, ...,  702,   24,  322],\n",
              "       [   0,    0,    0, ...,  703,   58, 3846],\n",
              "       [   0,    0,    0, ...,    7,   53, 1062],\n",
              "       ...,\n",
              "       [   0,    0,    0, ...,    5, 3125, 3170],\n",
              "       [   0,    0,    0, ...,   15, 1781,  471],\n",
              "       [   0,    0,    0, ...,    4,  266, 1813]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ],
      "source": [
        "X_train_seq_pad = pad_sequences(X_train_seq, padding_length)\n",
        "X_test_seq_pad = pad_sequences(X_test_seq, padding_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "84/84 [==============================] - 3s 7ms/step - loss: 0.2993 - accuracy: 0.6957 - val_loss: 0.2795 - val_accuracy: 0.7167\n",
            "Epoch 2/10\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.2613 - accuracy: 0.7089 - val_loss: 0.2055 - val_accuracy: 0.7100\n",
            "Epoch 3/10\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.2169 - accuracy: 0.7188 - val_loss: 0.2016 - val_accuracy: 0.7167\n",
            "Epoch 4/10\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.2116 - accuracy: 0.7176 - val_loss: 0.2023 - val_accuracy: 0.7167\n",
            "Epoch 5/10\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.1956 - accuracy: 0.7294 - val_loss: 0.2037 - val_accuracy: 0.7167\n",
            "Epoch 6/10\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.1990 - accuracy: 0.7167 - val_loss: 0.2024 - val_accuracy: 0.7178\n",
            "Epoch 7/10\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.1955 - accuracy: 0.7317 - val_loss: 0.2027 - val_accuracy: 0.7167\n",
            "Epoch 8/10\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.2167 - accuracy: 0.7115 - val_loss: 0.2051 - val_accuracy: 0.7167\n",
            "Epoch 9/10\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.1962 - accuracy: 0.7179 - val_loss: 0.2058 - val_accuracy: 0.7156\n",
            "Epoch 10/10\n",
            "84/84 [==============================] - 0s 4ms/step - loss: 0.1866 - accuracy: 0.7327 - val_loss: 0.2094 - val_accuracy: 0.7167\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train_seq_pad, y_train_cat, validation_data=(X_test_seq_pad, y_test_cat), batch_size=batch_size, epochs=10, callbacks=[early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_18\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_72 (Dense)             (None, 178)               31862     \n_________________________________________________________________\ndense_73 (Dense)             (None, 512)               91648     \n_________________________________________________________________\ndense_74 (Dense)             (None, 256)               131328    \n_________________________________________________________________\ndense_75 (Dense)             (None, 64)                16448     \n_________________________________________________________________\ndense_76 (Dense)             (None, 64)                4160      \n_________________________________________________________________\ndense_77 (Dense)             (None, 32)                2080      \n_________________________________________________________________\ndense_78 (Dense)             (None, 32)                1056      \n_________________________________________________________________\ndense_79 (Dense)             (None, 16)                528       \n_________________________________________________________________\ndense_80 (Dense)             (None, 16)                272       \n_________________________________________________________________\ndense_81 (Dense)             (None, 8)                 136       \n_________________________________________________________________\ndense_82 (Dense)             (None, 8)                 72        \n_________________________________________________________________\ndense_83 (Dense)             (None, 2)                 18        \n=================================================================\nTotal params: 279,608\nTrainable params: 279,608\nNon-trainable params: 0\n_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "source": [
        "### Prediction presentation"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Treść wypowiedzi:\n",
            "['i', 'co', 'by', 'być', 'tutaj', 'nie', 'powiedzieć', 'złe', 'bo', 'zawsze', 'krytyk', 'się', 'znajda', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'to', 'Polska', 'w', 'moment', 'start', 'w', '89', 'rok', 'była', 'na', 'poziom', 'Białoruś', 'i', 'Ukraina', 'ukraina', 'czyli', 'przeciętny', 'Polak', 'wytwarzać', 'tyle', 'to', 'dochód', 'narodowy', 'ile', 'Białorusin', 'i', 'Ukrainiec', 'tam', 'minimalny', 'różnica', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'dolar', 'na', 'głowa', 'no', 'i', 'po', '25', 'lato', 'być', 'w', 'tym', 'miejsce', 'że', 'my', 'być', 'trzy', 'trzy', 'trzy', 'trzy', 'trzy', 'trzy', 'trzy', 'trzy', 'trzy', 'trzy', 'trzy', 'trzy', 'raz', 'zamożny', 'od', 'Białorusin', 'i', 'Ukrainiec']\n",
            "Klasyfikacja:  0\n",
            "Predykcja:  [0.29, 0.71]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['w', 'rok', '2015', 'na', '35', 'kraj', 'w', 'Europa', '34', 'miejsce', 'zajmować', 'ochrona', 'zdrowie', 'w', 'Polska']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [0.4, 0.6]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['jeden', 'z', 'moi', 'mój', 'konkurent', 'Rafał', 'Trzaskowski', '–', 'przyp', 'demagog', 'głosować', 'przeciwko', 'ustawa', 'obniżający', 'wiek', 'emerytalny', 'kiedy', 'być', 'poseł', 'przeciwko', 'moja', 'ustawa']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [0.41, 0.59]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['pani', 'poseł', 'mówić', 'że', 'sum', 'środek', 'zgromadzić', 'na', 'rezerwa', 'ogólny', 'budżet', 'państwo', 'jakoś', 'kosmicznie', 'wzrosły', 'on', 'wzrosły', 'o', 'mało', 'dużo', 'więcej', '15', '–', '20', '…', 'w', 'stosunek', 'do', 'zeszły', 'rok', 'dzisiaj', 'ta', 'sum', 'wynosić', 'oko', '250', 'milion', 'złoty']\n",
            "Klasyfikacja:  0\n",
            "Predykcja:  [0.35, 0.65]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['średnio', 'dzisiaj', 'nasze', 'blok', 'który', 'były', 'budować', 'kilkanaście', 'kilkanaście', 'kilkanaście', 'kilkanaście', 'kilkanaście', 'kilkanaście', 'kilkanaście', 'kilkanaście', 'kilkanaście', 'kilkanaście', 'kilkanaście', 'kilkanaście', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'kilkadziesiąt', 'lato', 'temu', 'na', 'jeden', 'megawatogodzina', 'energia', 'emitować', 'oko', '950', 'kilogram', 'CO2', 'nowa', 'inwestycja', 'w', 'Kozienice', 'który', 'być', 'ukończyć', 'w', 'przyszły', 'rok', 'to', 'być', '730', 'kgmegawatogodzinę']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [0.32, 0.68]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['z', 'początek', '2021', 'rok', 'NFZ', 'całkowicie', 'znieść', 'limit', 'w', 'zakres', 'świadczenie', 'psychiatryczny', 'dla', 'dziecko', 'i', 'młodzież']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [0.25, 0.75]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['w', 'mała', 'miasto', 'niemiecki', '200', '300', 'tysięczny', 'być', 'metro']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [0.4, 0.6]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['złożyć', 'być', 'projekt', 'który', 'nie', 'tylko', 'zakładać', 'zrównać', 'świadczenie', 'oba', 'oba', 'oba', 'oba', 'oba', 'oba', 'oba', 'oba', 'oba', 'oba', 'oba', 'oba', 'oba', 'oba', 'oba', 'oba', 'oba', 'oba', 'oba', 'oba', 'oba', 'oba', 'grupa', 'do', 'poziom', '1477', 'złoty', 'ale', 'również', 'zajmować', 'się', 'zasiłek', 'pielęgnacyjny', 'który', 'wynosić', 'obecnie', '153', 'złoty', '…', 'PiS', 'my', 'ten', 'projekt', 'zamrozić']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [0.41, 0.59]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['Kampania', 'kampania', '„', 'Krak', 'to', 'stan', 'umysł', '”', 'za', 'który', 'miasto', 'w', 'ubiegły', 'rokuzapłaciło', '200', 'tys', 'złoty', 'billboard', 'i', 'ogłoszenie', 'prasowy', 'w', '5', 'polski', 'miasto']\n",
            "Klasyfikacja:  0\n",
            "Predykcja:  [0.34, 0.66]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['już', 'nie', 'mówić', 'nawet', 'o', 'Stany', 'zjednoczyć', 'gdzie', 'sześć', 'sześć', 'sześć', 'sześć', 'sześć', 'sześć', 'sześć', 'sześć', 'sześć', 'sześć', 'sześć', 'sześć', 'raz', 'dużo', 'więcej', 'pieniądz', 'być', 'przekazywać', 'na', 'onkologia', 'nie', 'mówić', 'nawet', 'o', 'Francja', 'i', 'wielki', 'Brytania', 'brytania', 'czyli', 'kraj', 'unia', 'gdzie', 'się', 'przeznaczać', 'trzy', 'trzy', 'trzy', 'trzy', 'trzy', 'trzy', 'trzy', 'trzy', 'trzy', 'trzy', 'trzy', 'trzy', 'raz', 'dużo', 'więcej', 'pieniądz', 'ale', 'wystarczyć', 'powiedzieć', 'o', 'Czech', 'gdzie', 'się', 'przeznaczać', 'dwa', 'dwa', 'dwa', 'dwa', 'dwa', 'dwa', 'dwa', 'dwa', 'dwa', 'raz', 'pieniądz', 'na', 'onkologia']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [0.33, 0.67]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['z', 'ten', 'minione', '8', 'lato', '…', 'Polska', 'była', 'jedyna', 'kraj', 'w', 'cały', 'unia', 'europejski', 'który', 'nie', 'miał', 'okres', 'spadek', 'PKB', 'tylko', 'cały', 'czas', 'u', 'my', 'wzrastać']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [0.39, 0.61]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['maksymalnie', 'w', 'nasz', 'strategia', 'przewidywać', 'się', '6000', 'megawat', 'pozyskiwać', 'z', 'energia', 'jądrowy']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [0.25, 0.75]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['cały', 'budżet', 'Warszawa', 'warszawa', 'wynosić', 'oko', '13', 'miliard', 'rocznie']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [0.4, 0.6]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['tylko', 'platforma', 'mój', 'prawie', '35', 'kobieta', '…', 'żaden', 'inny', 'partia', 'się', 'nawet', 'nie', 'zbliżać', 'do', 'to']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [0.41, 0.59]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['zarówno', 'minister', 'polski', 'rząd', 'ale', 'także', 'prezydent', 'Andrzej', 'Duda', 'duda', 'rozpoczynać', 'taka', 'kampania', 'gospodarczy', 'współpraca', 'z', 'ten', 'kraj', 'do', 'który', 'od', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'wiele', 'lato', 'nikt', 'z', 'polski', 'władza', 'nie', 'jeździć', 'czyli', 'to', 'mama', 'Azja', 'mama', 'Chiny', 'mama', 'Afryka']\n",
            "Klasyfikacja:  0\n",
            "Predykcja:  [0.33, 0.67]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['Warszawa', 'warszawa', '…', 'to', 'być', '…', 'najbardziej', 'zadłużyć', 'gmina', 'w', 'Polska']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [0.4, 0.6]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['480', 'milion', 'złoty', 'wydawać', 'obecnie', 'na', 'komunikacja', 'miejski']\n",
            "Klasyfikacja:  0\n",
            "Predykcja:  [0.37, 0.63]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['rząd', 'deklarować', 'że', 'w', 'marzec', 'przyjąć', 'pierwsza', 'grupa', 'sto', 'sto', 'sto', 'sto', 'sto', 'sto', 'sto', 'sto', 'sto', 'sto', 'sto', 'sto', 'sto', 'sto', 'sto', 'sto', 'sto', 'sto', 'sto', 'sto', 'sto', 'sto', 'sto', 'uchodźca', 'zostać', 'wysłać', 'oficer', 'łącznik', 'do', 'Grecja', 'żeby', 'weryfikować', 'podobno', 'zweryfikować', 'pierwsza', '67', 'osoba']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [0.39, 0.61]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['żyć', 'w', 'państwo', 'który', 'wysyłać', '100', '000', 'kontrola', 'podatkowy', 'rocznie', 'z', 'który', 'tylko', '⅕', 'dawać', 'jakiś', 'efekt']\n",
            "Klasyfikacja:  0\n",
            "Predykcja:  [0.3, 0.7]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['uważać', 'że', 'należeć', 'wyprowadzić', 'religia', 'z', 'szkoła', 'a', 'te', '15', 'miliard', 'spożytkować', 'na', 'coś', 'lepsze']\n",
            "Klasyfikacja:  0\n",
            "Predykcja:  [0.36, 0.64]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['według', 'raport', '„', 'praca', 'i', 'przedsiębiorczość', 'kobieta', 'potencjał', 'do', 'wykorzystanie', 'w', 'Polska', '”', 'wskaźnik', 'aktywność', 'zawodowy', 'kobieta', 'w', 'Polska', 'wynosić', 'obecnie', '614', 'oznaczać', 'to', 'że', 'aż', '4', 'na', '10', 'Polek', 'w', 'wiek', 'produkcyjny', 'nie', 'pracować']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [0.26, 0.74]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['w', 'test', 'Pisa', 'z', 'matematyka', 'być', 'wysoce', 'wysoko', 'niż', 'Finlandia']\n",
            "Klasyfikacja:  0\n",
            "Predykcja:  [0.4, 0.6]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['szkolnictwo', 'zawodowy', 'co', 'wynikać', '…', 'z', 'raport', 'wysoki', 'izba', 'kontrola', 'nie', 'być', 'przystosować', 'do', 'rynek', 'praca']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [0.33, 0.67]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['na', 'sam', 'odsetek', 'od', 'dług', 'miasto', 'wydawać', 'rocznie', '35', 'milion', 'złoty']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [0.4, 0.6]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['nie', 'być', 'to', 'wina', 'nadzór', 'finansowy', 'nadzór', 'finansowy', 'dopiero', 'w', 'październik', '2013', 'rok', 'przyjąć', 'trzeba', 'być', 'zrobić', 'bardzo', 'dokładny', 'audyt', 'i', 'sprawdzić', 'co', 'się', 'dzieje', 'żeby', 'można', 'być', 'potem', 'postawić', 'ewentualnie', 'w', 'stan', 'upadłość']\n",
            "Klasyfikacja:  0\n",
            "Predykcja:  [0.41, 0.59]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['Sam', 'ustawa', 'o', 'media', 'medium', 'publiczny', 'zakładać', 'już', 'równy', 'stosunek', 'do', 'uczestnik', 'dyskurs', 'publiczny', 'że', 'to', 'być', 'obowiązek', 'media', 'medium', 'publiczny']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [0.25, 0.75]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['Paweł', 'Wojtunik', 'ależ', 'sejm', 'nie', 'być', 'opisać', 'nigdzie', 'w', 'prawie', 'jako', 'instytucja', 'do', 'który', 'nie', 'wolno', 'wejść', 'na', 'przeszukanie', 'być', 'jeden', 'podstawowy', 'zasada', 'przy', 'przeszukanie', 'instytucja', 'państwowy', 'a', 'taka', 'być', 'sejm', 'należeć', 'o', 'zamiar', 'to', 'być', 'równoznaczny', 'z', 'rozpoczęcie', 'przeszukanie', 'o', 'zamiar', 'przy', 'rozpoczęcie', 'przeszukanie', 'zawiadomić', 'kierownik', 'ten', 'instytucja', 'dlatego', 'że', 'ten', 'kierownik', '…', 'Monika', 'Olejnik', 'właśnie', 'o', 'tym', 'mówięPaweł', 'Wojtunik', 'dlatego', 'że', 'ta', 'osoba', 'mój', 'prawo', 'wyznaczyć', 'pracownik', 'do', 'udział', 'w', 'tym', 'przeszukanie']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [0.35, 0.65]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['a', 'co', 'mama', 'w', 'ustawa', 'który', 'zostać', 'dziś', 'w', 'noc', 'przegłosować', 'otwarty', 'zostać', 'ścieżek', 'że', 'już', 'nie', 'trzeba', 'być', 'prowadzić', 'konsultacja', 'społeczny', '–', 'ani', 'z', 'samorząd', 'lokalny', 'ani', 'z', 'prezydent', 'miast', 'ani', 'z', 'związek', 'zawodowy', 'a', 'być', 'można', 'na', 'podstawa', 'ustawa', 'podjąć', 'decyzja', 'o', 'likwidacja', 'kopalnia']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [0.37, 0.63]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['dwa', 'dwa', 'dwa', 'dwa', 'dwa', 'dwa', 'sędzia', 'wybrana', 'w', 'grudzień', 'orzekać', 'być', 'w', 'skład', 'TK']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [0.4, 0.6]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['chiński', 'produkcja', 'za', 'trzy', 'trzy', 'trzy', 'trzy', 'trzy', 'trzy', 'trzy', 'trzy', 'trzy', 'trzy', 'trzy', 'trzy', 'kwartał', 'to', '26', 'miliard', 'ton', 'węgiel']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [0.4, 0.6]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['w', 'sprawa', 'budżetowy', 'być', 'to', 'o', 'tyle', 'istotny', 'że', 'przyjęcie', 'perspektywa', 'finansowy', 'wymagać', 'zgoda', 'z', 'strona', 'parlament', 'europejski']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [0.4, 0.6]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['PiS', 'obiecać', 'budowa', 'tani', 'mieszkanie', 'na', 'wynajem', 'w', 'rama', 'mieszkanie', '”', '–', 'nie', 'zrobić']\n",
            "Klasyfikacja:  0\n",
            "Predykcja:  [0.37, 0.63]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['w', 'ranking', 'miast', 'wojewódzki', 'Łódź', 'łódź', 'być', 'druga', 'od', 'koniec', 'miasto', 'pod', 'względem', 'wielkość', 'bezrobocie', '127', 'bezrobocie', 'przed', 'Białystok', '139', 'dla', 'przykład', 'w', 'Poznań', 'stopa', 'bezrobocie', 'wynosić', '41', 'w', 'Warszawa', 'warszawa', '48', 'w', 'Wrocław', '56', 'w', 'Krak', '61', 'a', 'w', 'gdański', '69']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [0.28, 0.72]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['w', 'Wrocław', 'na', '1000', 'mieszkaniec', 'przypadać', 'aż', '632', 'samochód']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [0.38, 0.62]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['podpisać', 'ten', 'decyzja', 'reprywatyzacyjny', 'kamienica', 'przy', 'ulica', 'Noakowski', '16', 'urzędnik', 'prezydent', 'Lech', 'Kaczyński']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [0.33, 0.67]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['nie', 'zostać', 'ruszyć', 'procedura', 'na', 'etap', 'postępowanie', 'przygotowawczy', '…', 'być', 'co', 'do', 'zasada', 'inkwizycyjny']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [0.34, 0.66]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['jeśli', 'chodzić', 'o', 'obciążenie', 'podatkowy', 'zarówno', 'w', 'postać', 'podatek', 'pośredni', 'jak', 'i', 'bezpośredni', 'Polska', 'na', 'tło', 'inny', 'kraj', 'unia', 'europejski', 'być', 'średniak', 'znajdować', 'znajdywać', 'się', 'gdzieś', 'tak', 'pośrodku', 'stawek']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [0.37, 0.63]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['poprzeć', 'być', 'PiS', 'pani', 'KidawęBłońską', 'na', 'Marszałek', 'marszałek', 'sejm']\n",
            "Klasyfikacja:  0\n",
            "Predykcja:  [0.4, 0.6]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['Polska', 'posiadać', 'jeden', 'z', 'niski', 'w', 'Europa', 'współczynnik', 'możliwy', 'mobilizacja', 'rezerwa']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [0.4, 0.6]\n",
            "================================================\n",
            "Treść wypowiedzi:\n",
            "['przypominać', 'że', 'to', 'być', 'mocarstwo', 'Rosja', 'który', 'mój', 'doktryna', 'na', 'prewencyjny', 'użycie', 'taki', 'broń', 'atomowy']\n",
            "Klasyfikacja:  1\n",
            "Predykcja:  [0.33, 0.67]\n",
            "================================================\n"
          ]
        }
      ],
      "source": [
        "# np.array([X_test_seq[100]])\n",
        "# prediction = model.predict(np.array([X_test_seq[100]]))\n",
        "\n",
        "for numb in range(100, 140):\n",
        "    print('Treść wypowiedzi:')\n",
        "    print(X_test.iloc[numb])\n",
        "    print('Klasyfikacja: ', y_test.iloc[numb])\n",
        "    prediction = model.predict(np.array([X_test_seq_pad[numb]]))\n",
        "    print('Predykcja: ', [round(prc, 2) for prc in prediction[0]])\n",
        "    # print(X_test_seq_pad[numb])\n",
        "    print('================================================')\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8f79i215ns_O"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcxV7qHxees3"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qc7kl2ODnuk9"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}